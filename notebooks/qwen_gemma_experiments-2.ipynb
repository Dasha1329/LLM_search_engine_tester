{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74fc2ce2-8b1e-41b2-810d-4fb4f0724350",
   "metadata": {},
   "source": [
    "# Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abca944b-1e23-4b0d-bf68-5354b570effb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Using cached transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "Downloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.7/450.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.0/462.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.27.1 regex-2024.11.6 safetensors-0.5.2 tokenizers-0.21.0 transformers-4.47.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f707a9-21a7-488e-8e98-05e87455ac50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sglang[all]\n",
      "  Downloading sglang-0.4.1.post4-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from sglang[all]) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sglang[all]) (4.66.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from sglang[all]) (1.26.4)\n",
      "Requirement already satisfied: IPython in /opt/conda/lib/python3.11/site-packages (from sglang[all]) (8.16.1)\n",
      "Collecting setproctitle (from sglang[all])\n",
      "  Using cached setproctitle-1.3.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.11/site-packages (from IPython->sglang[all]) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from IPython->sglang[all]) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from IPython->sglang[all]) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from IPython->sglang[all]) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.11/site-packages (from IPython->sglang[all]) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from IPython->sglang[all]) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from IPython->sglang[all]) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from IPython->sglang[all]) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.11/site-packages (from IPython->sglang[all]) (5.11.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from IPython->sglang[all]) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->sglang[all]) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->sglang[all]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->sglang[all]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->sglang[all]) (2023.7.22)\n",
      "Collecting anthropic>=0.20.0 (from sglang[all])\n",
      "  Using cached anthropic-0.42.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting litellm>=1.0.0 (from sglang[all])\n",
      "  Downloading litellm-1.57.5-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting openai>=1.0 (from sglang[all])\n",
      "  Downloading openai-1.59.6-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting tiktoken (from sglang[all])\n",
      "  Using cached tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from sglang[all]) (2.4.0)\n",
      "Collecting vllm<=0.6.4.post1,>=0.6.3.post1 (from sglang[all])\n",
      "  Using cached vllm-0.6.4.post1-cp38-abi3-manylinux1_x86_64.whl.metadata (10 kB)\n",
      "Collecting cuda-python (from sglang[all])\n",
      "  Using cached cuda_python-12.6.2.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "INFO: pip is looking at multiple versions of sglang[srt] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting sglang[all]\n",
      "  Downloading sglang-0.4.1.post3-py3-none-any.whl.metadata (22 kB)\n",
      "  Downloading sglang-0.4.1.post2-py3-none-any.whl.metadata (22 kB)\n",
      "  Downloading sglang-0.4.1.post1-py3-none-any.whl.metadata (22 kB)\n",
      "  Downloading sglang-0.4.1-py3-none-any.whl.metadata (22 kB)\n",
      "  Using cached sglang-0.4.0.post2-py3-none-any.whl.metadata (22 kB)\n",
      "  Using cached sglang-0.4.0.post1-py3-none-any.whl.metadata (22 kB)\n",
      "  Using cached sglang-0.4.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting vllm>=0.6.3.post1 (from sglang[all])\n",
      "  Downloading vllm-0.6.6.post1-cp38-abi3-manylinux1_x86_64.whl.metadata (11 kB)\n",
      "INFO: pip is still looking at multiple versions of sglang[srt] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting sglang[all]\n",
      "  Using cached sglang-0.3.6.post3-py3-none-any.whl.metadata (22 kB)\n",
      "  Using cached sglang-0.3.6.post2-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from anthropic>=0.20.0->sglang[all]) (4.0.0)\n",
      "Collecting distro<2,>=1.7.0 (from anthropic>=0.20.0->sglang[all])\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from anthropic>=0.20.0->sglang[all])\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from anthropic>=0.20.0->sglang[all])\n",
      "  Using cached jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from anthropic>=0.20.0->sglang[all])\n",
      "  Downloading pydantic-2.10.5-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from anthropic>=0.20.0->sglang[all]) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /opt/conda/lib/python3.11/site-packages (from anthropic>=0.20.0->sglang[all]) (4.12.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->IPython->sglang[all]) (0.8.3)\n",
      "Collecting aiohttp (from litellm>=1.0.0->sglang[all])\n",
      "  Using cached aiohttp-3.11.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from litellm>=1.0.0->sglang[all]) (8.1.7)\n",
      "Collecting httpx<1,>=0.23.0 (from anthropic>=0.20.0->sglang[all])\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /opt/conda/lib/python3.11/site-packages (from litellm>=1.0.0->sglang[all]) (6.8.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /opt/conda/lib/python3.11/site-packages (from litellm>=1.0.0->sglang[all]) (3.1.2)\n",
      "Collecting jsonschema<5.0.0,>=4.22.0 (from litellm>=1.0.0->sglang[all])\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting python-dotenv>=0.2.0 (from litellm>=1.0.0->sglang[all])\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: tokenizers in /opt/conda/lib/python3.11/site-packages (from litellm>=1.0.0->sglang[all]) (0.21.0)\n",
      "Collecting uvloop<0.22.0,>=0.21.0 (from litellm>=1.0.0->sglang[all])\n",
      "  Using cached uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->IPython->sglang[all]) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->IPython->sglang[all]) (0.2.8)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.11/site-packages (from tiktoken->sglang[all]) (2024.11.6)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from vllm>=0.6.3.post1->sglang[all]) (5.9.5)\n",
      "Collecting sentencepiece (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting blake3 (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Downloading blake3-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting py-cpuinfo (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: transformers>=4.45.2 in /opt/conda/lib/python3.11/site-packages (from vllm>=0.6.3.post1->sglang[all]) (4.47.1)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.11/site-packages (from vllm>=0.6.3.post1->sglang[all]) (5.27.3)\n",
      "Collecting fastapi!=0.113.*,!=0.114.0,>=0.107.0 (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn[standard] (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting prometheus_client>=0.18.0 (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.11/site-packages (from vllm>=0.6.3.post1->sglang[all]) (10.4.0)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting lm-format-enforcer<0.11,>=0.10.9 (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached lm_format_enforcer-0.10.9-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting outlines==0.1.11 (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting lark==1.2.2 (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting xgrammar>=0.1.6 (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Downloading xgrammar-0.1.9-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: filelock>=3.16.1 in /opt/conda/lib/python3.11/site-packages (from vllm>=0.6.3.post1->sglang[all]) (3.16.1)\n",
      "Collecting partial-json-parser (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyzmq in /opt/conda/lib/python3.11/site-packages (from vllm>=0.6.3.post1->sglang[all]) (25.1.1)\n",
      "Collecting msgspec (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting gguf==0.10.0 (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting mistral_common>=1.5.0 (from mistral_common[opencv]>=1.5.0->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached mistral_common-1.5.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from vllm>=0.6.3.post1->sglang[all]) (6.0.1)\n",
      "Collecting einops (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting compressed-tensors==0.8.1 (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached compressed_tensors-0.8.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting depyf==0.18.0 (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.11/site-packages (from vllm>=0.6.3.post1->sglang[all]) (3.0.0)\n",
      "Collecting ray>=2.9 (from ray[default]>=2.9->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached ray-2.40.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Collecting nvidia-ml-py>=12.560.30 (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting torch (from sglang[all])\n",
      "  Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchvision==0.20.1 (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting xformers==0.0.28.post3 (from vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached xformers-0.0.28.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->sglang[all]) (3.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->sglang[all]) (2024.6.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->sglang[all])\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->sglang[all])\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->sglang[all])\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch->sglang[all]) (9.1.0.70)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->sglang[all])\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->sglang[all])\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->sglang[all])\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->sglang[all])\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->sglang[all])\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch->sglang[all])\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch->sglang[all])\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->sglang[all])\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch->sglang[all])\n",
      "  Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch->sglang[all])\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting astor (from depyf==0.18.0->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from depyf==0.18.0->vllm>=0.6.3.post1->sglang[all]) (0.3.8)\n",
      "Collecting interegular (from outlines==0.1.11->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: nest_asyncio in /opt/conda/lib/python3.11/site-packages (from outlines==0.1.11->vllm>=0.6.3.post1->sglang[all]) (1.5.8)\n",
      "Collecting diskcache (from outlines==0.1.11->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: referencing in /opt/conda/lib/python3.11/site-packages (from outlines==0.1.11->vllm>=0.6.3.post1->sglang[all]) (0.30.2)\n",
      "Collecting pycountry (from outlines==0.1.11->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting airportsdata (from outlines==0.1.11->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached airportsdata-20241001-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch->sglang[all]) (1.3.0)\n",
      "Collecting decord (from sglang[all])\n",
      "  Using cached decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\n",
      "Collecting hf_transfer (from sglang[all])\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.11/site-packages (from sglang[all]) (0.27.1)\n",
      "Collecting modelscope (from sglang[all])\n",
      "  Downloading modelscope-1.22.0-py3-none-any.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting orjson (from sglang[all])\n",
      "  Downloading orjson-3.10.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of sglang[runtime-common] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting vllm>=0.6.3.post1 (from sglang[all])\n",
      "  Downloading vllm-0.6.6-cp38-abi3-manylinux1_x86_64.whl.metadata (11 kB)\n",
      "  Using cached vllm-0.6.5-cp38-abi3-manylinux1_x86_64.whl.metadata (11 kB)\n",
      "Collecting outlines<0.1,>=0.0.43 (from vllm<=0.6.4.post1,>=0.6.3.post1->sglang[all])\n",
      "  Using cached outlines-0.0.46-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting compressed-tensors==0.8.0 (from vllm<=0.6.4.post1,>=0.6.3.post1->sglang[all])\n",
      "  Using cached compressed_tensors-0.8.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from sglang[all]) (23.2)\n",
      "Collecting python-multipart (from sglang[all])\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pyzmq (from vllm<=0.6.4.post1,>=0.6.3.post1->sglang[all])\n",
      "  Using cached pyzmq-26.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting torchao (from sglang[all])\n",
      "  Using cached torchao-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.11/site-packages (from outlines<0.1,>=0.0.43->vllm<=0.6.4.post1,>=0.6.3.post1->sglang[all]) (0.60.0)\n",
      "Collecting datasets (from outlines<0.1,>=0.0.43->vllm<=0.6.4.post1,>=0.6.3.post1->sglang[all])\n",
      "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting pyairports (from outlines<0.1,>=0.0.43->vllm<=0.6.4.post1,>=0.6.3.post1->sglang[all])\n",
      "  Using cached pyairports-2.1.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->IPython->sglang[all]) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->IPython->sglang[all]) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->IPython->sglang[all]) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->IPython->sglang[all]) (1.16.0)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->anthropic>=0.20.0->sglang[all])\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->anthropic>=0.20.0->sglang[all])\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm>=1.0.0->sglang[all]) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.0.0->sglang[all]) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.0.0->sglang[all]) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.0.0->sglang[all]) (2023.7.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.0.0->sglang[all]) (0.10.6)\n",
      "Collecting tiktoken (from sglang[all])\n",
      "  Using cached tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting opencv-python-headless<5.0.0,>=4.0.0 (from mistral_common[opencv]>=1.5.0->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->anthropic>=0.20.0->sglang[all])\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.9.0->anthropic>=0.20.0->sglang[all])\n",
      "  Using cached pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.9->ray[default]>=2.9->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting aiosignal (from ray>=2.9->ray[default]>=2.9->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting frozenlist (from ray>=2.9->ray[default]>=2.9->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.45.2->vllm>=0.6.3.post1->sglang[all]) (0.5.2)\n",
      "Collecting pybind11 (from xgrammar>=0.1.6->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting pytest (from xgrammar>=0.1.6->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached pytest-8.3.4-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->litellm>=1.0.0->sglang[all])\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->litellm>=1.0.0->sglang[all])\n",
      "  Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->litellm>=1.0.0->sglang[all])\n",
      "  Using cached propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->litellm>=1.0.0->sglang[all])\n",
      "  Using cached yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached watchfiles-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached websockets-14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets->outlines<0.1,>=0.0.43->vllm<=0.6.4.post1,>=0.6.3.post1->sglang[all])\n",
      "  Using cached pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm<=0.6.4.post1,>=0.6.3.post1->sglang[all]) (2.2.2)\n",
      "Collecting requests (from sglang[all])\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm (from sglang[all])\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets->outlines<0.1,>=0.0.43->vllm<=0.6.4.post1,>=0.6.3.post1->sglang[all])\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets->outlines<0.1,>=0.0.43->vllm<=0.6.4.post1,>=0.6.3.post1->sglang[all])\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba->outlines<0.1,>=0.0.43->vllm<=0.6.4.post1,>=0.6.3.post1->sglang[all]) (0.43.0)\n",
      "Collecting iniconfig (from pytest->xgrammar>=0.1.6->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest->xgrammar>=0.1.6->vllm>=0.6.3.post1->sglang[all])\n",
      "  Using cached pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm<=0.6.4.post1,>=0.6.3.post1->sglang[all]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm<=0.6.4.post1,>=0.6.3.post1->sglang[all]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm<=0.6.4.post1,>=0.6.3.post1->sglang[all]) (2024.1)\n",
      "Using cached sglang-0.3.6.post2-py3-none-any.whl (479 kB)\n",
      "Using cached anthropic-0.42.0-py3-none-any.whl (203 kB)\n",
      "Downloading litellm-1.57.5-py3-none-any.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.59.6-py3-none-any.whl (454 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached vllm-0.6.4.post1-cp38-abi3-manylinux1_x86_64.whl (198.9 MB)\n",
      "Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
      "Using cached compressed_tensors-0.8.0-py3-none-any.whl (86 kB)\n",
      "Using cached gguf-0.10.0-py3-none-any.whl (71 kB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
      "Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "Using cached xformers-0.0.28.post3-cp311-cp311-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "Using cached outlines-0.0.46-py3-none-any.whl (101 kB)\n",
      "Using cached cuda_python-12.6.2.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.7 MB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached lm_format_enforcer-0.10.9-py3-none-any.whl (43 kB)\n",
      "Using cached interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Using cached mistral_common-1.5.1-py3-none-any.whl (6.5 MB)\n",
      "Using cached sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Using cached nvidia_ml_py-12.560.30-py3-none-any.whl (40 kB)\n",
      "Using cached prometheus_client-0.21.1-py3-none-any.whl (54 kB)\n",
      "Using cached prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl (19 kB)\n",
      "Downloading pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached pyzmq-26.2.0-cp311-cp311-manylinux_2_28_x86_64.whl (869 kB)\n",
      "Using cached ray-2.40.0-cp311-cp311-manylinux2014_x86_64.whl (67.0 MB)\n",
      "Using cached uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "Downloading xgrammar-0.1.9-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (340 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m340.8/340.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached aiohttp-3.11.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Using cached decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
      "Using cached einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading modelscope-1.22.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.4/130.4 kB\u001b[0m \u001b[31m374.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Using cached torchao-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (4.1 MB)\n",
      "Using cached uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
      "Using cached msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
      "Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Using cached opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "Using cached propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "Using cached starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "Using cached watchfiles-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
      "Using cached websockets-14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
      "Using cached yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "Using cached datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Using cached lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Using cached pyairports-2.1.1-py3-none-any.whl (371 kB)\n",
      "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
      "Using cached pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "Using cached pytest-8.3.4-py3-none-any.whl (343 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Using cached pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Using cached pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "Using cached iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: torchao, sentencepiece, pyairports, py-cpuinfo, nvidia-ml-py, cuda-python, xxhash, websockets, uvloop, triton, tqdm, sympy, requests, pyzmq, python-multipart, python-dotenv, pydantic-core, pycountry, pybind11, pyarrow, propcache, prometheus_client, pluggy, partial-json-parser, orjson, opencv-python-headless, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multiprocess, multidict, msgspec, msgpack, lark, jiter, interegular, iniconfig, httptools, hf_transfer, h11, frozenlist, einops, distro, diskcache, decord, annotated-types, aiohappyeyeballs, yarl, watchfiles, uvicorn, tiktoken, starlette, pytest, pydantic, nvidia-cusparse-cu12, modelscope, httpcore, gguf, aiosignal, prometheus-fastapi-instrumentator, nvidia-cusolver-cu12, lm-format-enforcer, jsonschema, httpx, fastapi, aiohttp, torch, sglang, ray, openai, mistral_common, anthropic, xgrammar, xformers, torchvision, litellm, datasets, compressed-tensors, outlines, vllm\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.0.0\n",
      "    Uninstalling triton-3.0.0:\n",
      "      Successfully uninstalled triton-3.0.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.1\n",
      "    Uninstalling tqdm-4.66.1:\n",
      "      Successfully uninstalled tqdm-4.66.1\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: pyzmq\n",
      "    Found existing installation: pyzmq 25.1.1\n",
      "    Uninstalling pyzmq-25.1.1:\n",
      "      Successfully uninstalled pyzmq-25.1.1\n",
      "  Attempting uninstall: prometheus_client\n",
      "    Found existing installation: prometheus-client 0.17.1\n",
      "    Uninstalling prometheus-client-0.17.1:\n",
      "      Successfully uninstalled prometheus-client-0.17.1\n",
      "  Attempting uninstall: pluggy\n",
      "    Found existing installation: pluggy 1.3.0\n",
      "    Uninstalling pluggy-1.3.0:\n",
      "      Successfully uninstalled pluggy-1.3.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
      "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.6.77\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
      "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
      "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
      "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.19.1\n",
      "    Uninstalling jsonschema-4.19.1:\n",
      "      Successfully uninstalled jsonschema-4.19.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.0\n",
      "    Uninstalling torch-2.4.0:\n",
      "      Successfully uninstalled torch-2.4.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.19.0\n",
      "    Uninstalling torchvision-0.19.0:\n",
      "      Successfully uninstalled torchvision-0.19.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.4.0 requires torch==2.4.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 annotated-types-0.7.0 anthropic-0.42.0 compressed-tensors-0.8.0 cuda-python-12.6.2.post1 datasets-3.2.0 decord-0.6.0 diskcache-5.6.3 distro-1.9.0 einops-0.8.0 fastapi-0.115.6 frozenlist-1.5.0 gguf-0.10.0 h11-0.14.0 hf_transfer-0.1.9 httpcore-1.0.7 httptools-0.6.4 httpx-0.27.2 iniconfig-2.0.0 interegular-0.3.3 jiter-0.8.2 jsonschema-4.23.0 lark-1.2.2 litellm-1.57.5 lm-format-enforcer-0.10.9 mistral_common-1.5.1 modelscope-1.22.0 msgpack-1.1.0 msgspec-0.19.0 multidict-6.1.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-ml-py-12.560.30 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 openai-1.59.6 opencv-python-headless-4.10.0.84 orjson-3.10.14 outlines-0.0.46 partial-json-parser-0.2.1.1.post5 pluggy-1.5.0 prometheus-fastapi-instrumentator-7.0.0 prometheus_client-0.21.1 propcache-0.2.1 py-cpuinfo-9.0.0 pyairports-2.1.1 pyarrow-18.1.0 pybind11-2.13.6 pycountry-24.6.1 pydantic-2.10.5 pydantic-core-2.27.2 pytest-8.3.4 python-dotenv-1.0.1 python-multipart-0.0.20 pyzmq-26.2.0 ray-2.40.0 requests-2.32.3 sentencepiece-0.2.0 sglang-0.3.6.post2 starlette-0.41.3 sympy-1.13.1 tiktoken-0.7.0 torch-2.5.1 torchao-0.7.0 torchvision-0.20.1 tqdm-4.67.1 triton-3.1.0 uvicorn-0.34.0 uvloop-0.21.0 vllm-0.6.4.post1 watchfiles-1.0.3 websockets-14.1 xformers-0.0.28.post3 xgrammar-0.1.9 xxhash-3.5.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"sglang[all]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61ef3c79-6f38-454c-a300-0f85d8ab8eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://flashinfer.ai/whl/cu121/torch2.4/\n",
      "Collecting flashinfer\n",
      "  Downloading https://github.com/flashinfer-ai/flashinfer/releases/download/v0.2.0.post1/flashinfer-0.2.0.post1%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl (405.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.8/405.8 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of flashinfer to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading https://github.com/flashinfer-ai/flashinfer/releases/download/v0.2.0/flashinfer-0.2.0%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl (405.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.8/405.8 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://github.com/flashinfer-ai/flashinfer/releases/download/v0.1.6/flashinfer-0.1.6%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl (1322.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 GB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: flashinfer\n",
      "Successfully installed flashinfer-0.1.6+cu121torch2.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f45259-2c8e-45bc-ad00-8cad5bebddc8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate>=0.26.0\n",
      "  Downloading accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0) (2.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0) (0.27.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0) (0.4.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.6.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate>=0.26.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2023.7.22)\n",
      "Downloading accelerate-1.2.1-py3-none-any.whl (336 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m699.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "Successfully installed accelerate-1.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install 'accelerate>=0.26.0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c074a-9379-4e6c-9c5b-27738eb3e61d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "049e76b5-d31a-4174-bfd1-167e8d811410",
   "metadata": {},
   "source": [
    "**Шаблон обращения к LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9759db-1cf4-42e4-bb02-ba47408c7b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.Client(base_url=\"http://127.0.0.1:30000/v1\", api_key=\"None\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemma-2-9b-it\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant\"},\n",
    "        {\"role\": \"user\", \"content\": \"Расскажи анекдот\"},\n",
    "    ],\n",
    "    temperature=0.1,\n",
    "    max_tokens=500,\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ebef7a-ee28-411a-8069-8fce85c4d3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d27e900d-f313-4eb0-a6b3-ec742e62f8a6",
   "metadata": {},
   "source": [
    "# Qwen2-VL-72B-Instruct-AWQ (только текст (без картинок) работает)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1439973d-66b2-4bbd-bb94-353547e347e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.67%\n",
      "Accuracy for relevant: 95.01%\n",
      "Accuracy for irrelevant: 58.54%\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "client = openai.Client(base_url=\"http://127.0.0.1:30000/v1\", api_key=\"None\")\n",
    "\n",
    "# загружаю файлы (с примерами и правильными ответами)\n",
    "with open('files/RI разметка/3 итерация/items_1000.jsonl', 'r') as f:\n",
    "    items_data = [json.loads(line) for line in f]\n",
    "with open('files/RI разметка/3 итерация/data_vector_gt_1000.txt', 'r') as f:\n",
    "    ground_truth = f.read().strip().splitlines()\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, item in enumerate(items_data):\n",
    "    # print(type(item[1]))\n",
    "    # print(item[2])\n",
    "    request = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "Ты помощник поиска в маркетплейсе.\n",
    "Тебе необходимо определить, соответствует ли товар и его характеристики поисковому запросу.\n",
    "\n",
    "Классы запросов:\n",
    "relevant - товары, которые можно купить по указанному запросу\n",
    "irrelevant - товары, которые было бы странно увидеть по указанному запросу\n",
    "\n",
    "Товар:\n",
    "{item[1]['товар']}\n",
    "\n",
    "Запрос:\n",
    "{item[2]['запрос']}\n",
    "\n",
    "Определи релевантность запроса товару. Отвечай только \"relevant\" или \"irrelevant\". Не пиши объяснений и ничего больше.\n",
    "\"\"\"\n",
    "    }\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"Qwen2-VL-72B-Instruct-AWQ \",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \n",
    "             \"content\": \"You are a helpful AI assistant\"},\n",
    "            request\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=3,\n",
    "    )\n",
    "    \n",
    "    prediction = response.choices[0].message.content.strip().lower()\n",
    "    \n",
    "    # сравниваю предсказание с правильным ответом, исключая #N/A\n",
    "    ground_truth_label = ground_truth[i].strip().lower()\n",
    "    if ground_truth_label != '#n/a':\n",
    "        is_correct = prediction == ground_truth_label\n",
    "        results.append({\n",
    "            \"запрос\": item[2]['запрос'],\n",
    "            \"товар\": item[1]['товар'],\n",
    "            \"предсказание\": prediction,\n",
    "            \"реальность\": ground_truth_label,\n",
    "            \"is_correct\": is_correct\n",
    "        })\n",
    "\n",
    "# Подсчет общей Accuracy\n",
    "count_correct = sum(1 for item in results if item['is_correct'] == True)\n",
    "total_predictions = len(results)\n",
    "accuracy = count_correct / total_predictions if total_predictions > 0 else 0\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Accuracy для relevant\n",
    "relevant_correct = sum(1 for item in results if item['реальность'] == 'relevant' and item['is_correct'])\n",
    "relevant_total = sum(1 for item in results if item['реальность'] == 'relevant')\n",
    "relevant_accuracy = relevant_correct / relevant_total if relevant_total > 0 else 0\n",
    "\n",
    "# Accuracy для irrelevant\n",
    "irrelevant_correct = sum(1 for item in results if item['реальность'] == 'irrelevant' and item['is_correct'])\n",
    "irrelevant_total = sum(1 for item in results if item['реальность'] == 'irrelevant')\n",
    "irrelevant_accuracy = irrelevant_correct / irrelevant_total if irrelevant_total > 0 else 0\n",
    "\n",
    "print(f\"Accuracy for relevant: {relevant_accuracy:.2%}\")\n",
    "print(f\"Accuracy for irrelevant: {irrelevant_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7261765a-4c6c-4d92-959a-24db2c588589",
   "metadata": {},
   "source": [
    "# qwen32b\n",
    "**Базовый промпт:**\n",
    "\n",
    "Ты помощник поиска в маркетплейсе.\n",
    "Тебе необходимо определить, соответствует ли товар и его характеристики поисковому запросу.\n",
    "\n",
    "Классы запросов:\n",
    "relevant - товары, которые можно купить по указанному запросу\n",
    "irrelevant - товары, которые было бы странно увидеть по указанному запросу\n",
    "\n",
    "Товар:\n",
    "{item[1]['товар']}\n",
    "\n",
    "Запрос:\n",
    "{item[2]['запрос']}\n",
    "\n",
    "Определи релевантность запроса товару. Отвечай только \"relevant\" или \"irrelevant\". Не пиши объяснений и ничего больше.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c67b8fc-7da5-406a-9260-569f8e106164",
   "metadata": {},
   "source": [
    "# 1000 примеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad1e739f-9241-47f2-a17f-cbf082f5dcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.71%\n",
      "Accuracy for relevant: 90.96%\n",
      "Accuracy for irrelevant: 62.20%\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "client = openai.Client(base_url=\"http://127.0.0.1:30000/v1\", api_key=\"None\")\n",
    "\n",
    "# загружаю файлы (с примерами и правильными ответами)\n",
    "with open('files/RI разметка/3 итерация/items_1000.jsonl', 'r') as f:\n",
    "    items_data = [json.loads(line) for line in f]\n",
    "with open('files/RI разметка/3 итерация/data_vector_gt_1000.txt', 'r') as f:\n",
    "    ground_truth = f.read().strip().splitlines()\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, item in enumerate(items_data):\n",
    "    # print(type(item[1]))\n",
    "    # print(item[2])\n",
    "    request = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "Ты помощник поиска в маркетплейсе.\n",
    "Тебе необходимо определить, соответствует ли товар и его характеристики поисковому запросу.\n",
    "\n",
    "Классы запросов:\n",
    "relevant - товары, которые можно купить по указанному запросу\n",
    "irrelevant - товары, которые было бы странно увидеть по указанному запросу\n",
    "\n",
    "Товар:\n",
    "{item[1]['товар']}\n",
    "\n",
    "Запрос:\n",
    "{item[2]['запрос']}\n",
    "\n",
    "Определи релевантность запроса товару. Отвечай только \"relevant\" или \"irrelevant\". Не пиши объяснений и ничего больше.\n",
    "\"\"\"\n",
    "    }\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen32b\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \n",
    "             \"content\": \"You are a helpful AI assistant\"},\n",
    "            request\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=3,\n",
    "    )\n",
    "    \n",
    "    prediction = response.choices[0].message.content.strip().lower()\n",
    "    \n",
    "    # сравниваю предсказание с правильным ответом, исключая #N/A\n",
    "    ground_truth_label = ground_truth[i].strip().lower()\n",
    "    if ground_truth_label != '#n/a':\n",
    "        is_correct = prediction == ground_truth_label\n",
    "        results.append({\n",
    "            \"запрос\": item[2]['запрос'],\n",
    "            \"товар\": item[1]['товар'],\n",
    "            \"предсказание\": prediction,\n",
    "            \"реальность\": ground_truth_label,\n",
    "            \"is_correct\": is_correct\n",
    "        })\n",
    "\n",
    "# Подсчет общей Accuracy\n",
    "count_correct = sum(1 for item in results if item['is_correct'] == True)\n",
    "total_predictions = len(results)\n",
    "accuracy = count_correct / total_predictions if total_predictions > 0 else 0\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Accuracy для relevant\n",
    "relevant_correct = sum(1 for item in results if item['реальность'] == 'relevant' and item['is_correct'])\n",
    "relevant_total = sum(1 for item in results if item['реальность'] == 'relevant')\n",
    "relevant_accuracy = relevant_correct / relevant_total if relevant_total > 0 else 0\n",
    "\n",
    "# Accuracy для irrelevant\n",
    "irrelevant_correct = sum(1 for item in results if item['реальность'] == 'irrelevant' and item['is_correct'])\n",
    "irrelevant_total = sum(1 for item in results if item['реальность'] == 'irrelevant')\n",
    "irrelevant_accuracy = irrelevant_correct / irrelevant_total if irrelevant_total > 0 else 0\n",
    "\n",
    "print(f\"Accuracy for relevant: {relevant_accuracy:.2%}\")\n",
    "print(f\"Accuracy for irrelevant: {irrelevant_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228d922f-71c4-4eee-8fd8-4ce806d976e7",
   "metadata": {},
   "source": [
    "# Другие промпты, чтобы увеличить Accuracy for irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8aa3c00-2437-46cf-ab08-2d2115ee3ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.76%\n",
      "Accuracy for relevant: 96.67%\n",
      "Accuracy for irrelevant: 42.68%\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "client = openai.Client(base_url=\"http://127.0.0.1:30000/v1\", api_key=\"None\")\n",
    "\n",
    "# загружаю файлы (с примерами и правильными ответами)\n",
    "with open('files/RI разметка/3 итерация/items_1000.jsonl', 'r') as f:\n",
    "    items_data = [json.loads(line) for line in f]\n",
    "with open('files/RI разметка/3 итерация/data_vector_gt_1000.txt', 'r') as f:\n",
    "    ground_truth = f.read().strip().splitlines()\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, item in enumerate(items_data):\n",
    "    # print(type(item[1]))\n",
    "    # print(item[2])\n",
    "    request = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "Ты помощник поиска в маркетплейсе, специализирующийся на разметке негативных пар запрос-товар. Твоя задача — определить, абсолютно ли не соответствует товар поисковому запросу.\n",
    "**Классы запросов:**\n",
    "- **irrelevant:** Товар и запрос не имеют абсолютно никакой связи. Нет общих категорий, функциональности, ключевых слов или тематик. Показ такого товара в ответ на запрос будет полностью неожиданным и неуместным для пользователя. Пример: Запрос \"кофемашина\", а товар — \"велосипед\".\n",
    "- **relevant:** Любая связь, даже самая отдаленная или косвенная. Если товар и запрос могут быть хоть как-то связаны по смыслу, категории, использованию или контексту, классифицируй как \"relevant\". Пример: Запрос \"кофемашина\", а товар — \"кофейные зерна\".\n",
    "**Товар:**\n",
    "{item[1]['товар']}\n",
    "**Запрос:**\n",
    "{item[2]['запрос']}\n",
    "Отвечай только \"relevant\" или \"irrelevant\". Твой ответ должен быть максимально точным, чтобы избежать ложных негативов. Помни, \"irrelevant\" используется только в случае полного отсутствия связи между товаром и запросом.\n",
    "\"\"\"\n",
    "    }\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen32b\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \n",
    "             \"content\": \"You are a helpful AI assistant\"},\n",
    "            request\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=3,\n",
    "    )\n",
    "    \n",
    "    prediction = response.choices[0].message.content.strip().lower()\n",
    "    \n",
    "    # сравниваю предсказание с правильным ответом, исключая #N/A\n",
    "    ground_truth_label = ground_truth[i].strip().lower()\n",
    "    if ground_truth_label != '#n/a':\n",
    "        is_correct = prediction == ground_truth_label\n",
    "        results.append({\n",
    "            \"запрос\": item[2]['запрос'],\n",
    "            \"товар\": item[1]['товар'],\n",
    "            \"предсказание\": prediction,\n",
    "            \"реальность\": ground_truth_label,\n",
    "            \"is_correct\": is_correct\n",
    "        })\n",
    "\n",
    "# Подсчет общей Accuracy\n",
    "count_correct = sum(1 for item in results if item['is_correct'] == True)\n",
    "total_predictions = len(results)\n",
    "accuracy = count_correct / total_predictions if total_predictions > 0 else 0\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Accuracy для relevant\n",
    "relevant_correct = sum(1 for item in results if item['реальность'] == 'relevant' and item['is_correct'])\n",
    "relevant_total = sum(1 for item in results if item['реальность'] == 'relevant')\n",
    "relevant_accuracy = relevant_correct / relevant_total if relevant_total > 0 else 0\n",
    "\n",
    "# Accuracy для irrelevant\n",
    "irrelevant_correct = sum(1 for item in results if item['реальность'] == 'irrelevant' and item['is_correct'])\n",
    "irrelevant_total = sum(1 for item in results if item['реальность'] == 'irrelevant')\n",
    "irrelevant_accuracy = irrelevant_correct / irrelevant_total if irrelevant_total > 0 else 0\n",
    "\n",
    "print(f\"Accuracy for relevant: {relevant_accuracy:.2%}\")\n",
    "print(f\"Accuracy for irrelevant: {irrelevant_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2856977b-643f-48b6-a12b-88dfb4a6cdb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4b8d5f7-913e-4e9e-9ddd-193b4ffccba5",
   "metadata": {},
   "source": [
    "# Смотрю ошибки вручную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81e397f9-3bb2-499e-9b69-00886fb718f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "client = openai.Client(base_url=\"http://127.0.0.1:30000/v1\", api_key=\"None\")\n",
    "\n",
    "# загружаю файлы (с примерами и правильными ответами)\n",
    "with open('files/RI разметка/3 итерация/items_1000.jsonl', 'r') as f:\n",
    "    items_data = [json.loads(line) for line in f]\n",
    "with open('files/RI разметка/3 итерация/data_vector_gt_1000.txt', 'r') as f:\n",
    "    ground_truth = f.read().strip().splitlines()\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, item in enumerate(items_data):\n",
    "    # print(type(item[1]))\n",
    "    # print(item[2])\n",
    "    request = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "Ты помощник поиска в маркетплейсе.\n",
    "Тебе необходимо определить, соответствует ли товар и его характеристики поисковому запросу.\n",
    "\n",
    "Классы запросов:\n",
    "relevant - товары, которые можно купить по указанному запросу\n",
    "irrelevant - товары, которые было бы странно увидеть по указанному запросу\n",
    "\n",
    "Товар:\n",
    "{item[1]['товар']}\n",
    "\n",
    "Запрос:\n",
    "{item[2]['запрос']}\n",
    "\n",
    "Определи релевантность запроса товару. Отвечай только \"relevant\" или \"irrelevant\". Не пиши объяснений и ничего больше.\n",
    "\"\"\"\n",
    "    }\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen14b\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \n",
    "             \"content\": \"You are a helpful AI assistant\"},\n",
    "            request\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=3,\n",
    "    )\n",
    "    \n",
    "    prediction = response.choices[0].message.content.strip().lower()\n",
    "    \n",
    "    # сравниваю предсказание с правильным ответом, исключая #N/A\n",
    "    ground_truth_label = ground_truth[i].strip().lower()\n",
    "    if ground_truth_label != '#n/a':\n",
    "        is_correct = prediction == ground_truth_label\n",
    "        results.append({\n",
    "            \"запрос\": item[2]['запрос'],\n",
    "            \"товар\": item[1]['товар'],\n",
    "            \"предсказание\": prediction,\n",
    "            \"реальность\": ground_truth_label,\n",
    "            \"is_correct\": is_correct\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "913667e7-3736-4b5f-bb9b-a342a96d3039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple vision\n",
      "Двухкомпонентный Чехол ROCK Vision TPU-PC для Apple iPhone 8 Plus/7 Plus серый \n",
      "\n",
      "наволочка дакимакуры подушки арсений попов импровизация\n",
      "Подушка СувенирShop Комики \"Арсений Попов/Импровизация\" 35x35 \n",
      "\n",
      "корзинки вязанные\n",
      "Плед вязаный SELENA АЛИНА корзинка 220х200 см СЕРЫЙ \n",
      "\n",
      "стиральные машины под раковину\n",
      "Раковина над стиральной машиной Teymi Kati Pro 60х60, литьевой мрамор T50410 \n",
      "\n",
      "косметика для женшин\n",
      "Шампунь Kapous Professional С маслами авокадо и оливы 1000 мл \n",
      "\n",
      "ремешок mi band\n",
      "Смарт-часы Mi Smart Band 8 черный CN \n",
      "\n",
      "ugreen usb a 3.0 -usb c 3.1 купить\n",
      "Адаптер uGreen US276 (50533) USB 3.0-A to USB-C M/F Adpater серый \n",
      "\n",
      "игрушка для ребенка 1 год\n",
      "Музыкальная игрушка «Бубен: С Новым годом!» \n",
      "\n",
      "рамка qashqai j10\n",
      "Рамка NISSAN Qashqai 2007-2014, 9\" (Incar RNS-FC471) \n",
      "\n",
      "флешка микро самсунг\n",
      "Флешка Samsung BAR Plus 64ГБ Black (MUF-64BE4/APC) \n",
      "\n",
      "телевизор белый 32\n",
      "Рамка для телевизора Samsung 32'' The Frame White (VG-SCFT32WT) \n",
      "\n",
      "купить ремещок для часов касио amw 702d\n",
      "Ремешок для часов Casio AMW-702-7AV (10239913) черный \n",
      "\n",
      "кресло офисноее\n",
      "Кресло StoreForHome Goldfinger SF-832-BLUE, синий/золотистый \n",
      "\n",
      "наматрасник 140 200\n",
      "Матрас-топпер, тонкий матрас на диван IKEA Талжи, 140х200 см \n",
      "\n",
      "самокат micro\n",
      "Большая сумка Micro для переноски самоката \n",
      "\n",
      "фискарс черенок для, метлы\n",
      "Метла щетка Fiskars Patio Broom 1025927 162 см \n",
      "\n",
      "туалет petkit\n",
      "Гигиенические пакеты для автоматического туалета Petkit Pura X \n",
      "\n",
      "сумка рюкзак для фигурного катания\n",
      "Рюкзак на колесах фиолетовый MERMAID с наполнением сумка+пенал, Арт. 71377-3 \n",
      "\n",
      "гель для волос wella shockwaves\n",
      "Средство для укладки волос Wella Shockwaves Texture N'Shine 150 мл \n",
      "\n",
      "семена комнатных растений\n",
      "Саженцы бегония Агродекор AmeriHybrid Picotee Lace Pink AGRO1369 1 шт. \n",
      "\n",
      "походные наборы сибирский следопыт\n",
      "Туристический нож Сибирский Следопыт PF-PK-17, сталь/коричневый \n",
      "\n",
      "mid tower, micro atx, standard atx, usb 2.0 type a, gen1 type a, rgb вентиляторы\n",
      "Корпус для ПК Powercase Mistral Micro D3W ARGB \n",
      "\n",
      "штаны мужские\n",
      "Костюм Laconi для мужчин, 1261 S Alba, размер 50-182, тёмно-синий \n",
      "\n",
      "фитнес браслеты mi band 6\n",
      "Ремешок для Mi Band 5/6, фиолетовый \n",
      "\n",
      "матрас жесткий\n",
      "Ортопедический Матрас Darwin Breeze 90х190, беспружинный, 21 см высота, белый \n",
      "\n",
      "мегамаркет екб\n",
      "Кофе в зернах Умный выбор Irish Liqueur, 200 г \n",
      "\n",
      "xbox 360\n",
      "Игра SoulCalibur 5 (V) Русская Версия для Microsoft Xbox 360 \n",
      "\n",
      "hover h3 магнитола\n",
      "Переходная рамка для магнитолы Wide Media Great Wall Hover H3 2010-2014 9\" \n",
      "\n",
      "все для рыбалки\n",
      "Налобный светодиодный фонарь Double Light KX-1804 \n",
      "\n",
      "l7\n",
      "Чехол для ключа AA для LiXiang L7, L8, L9 \n",
      "\n",
      "iphone 7￼\n",
      "Чехол накладка для iPhone 7 с подкладкой из микрофибры / черный \n",
      "\n",
      "радиоуправляемые игрушки\n",
      "Центральный блок верхнего слайдера Align, T-Rex 450 Plus \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in results:\n",
    "    if not item['is_correct'] and item['реальность']=='irrelevant':\n",
    "        print(item['запрос'])\n",
    "        print(item['товар'], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ddb763-d6bd-47a8-815e-6f52a951f589",
   "metadata": {},
   "source": [
    "# Добавила характеристики товаров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81c451c2-c818-474f-b4c3-2991a5e6aef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.76%\n",
      "Accuracy for relevant: 88.23%\n",
      "Accuracy for irrelevant: 78.05%\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "client = openai.Client(base_url=\"http://127.0.0.1:30000/v1\", api_key=\"None\")\n",
    "\n",
    "# загружаю файлы (с примерами и правильными ответами)\n",
    "with open('files/RI разметка/3 итерация/items_1000.jsonl', 'r') as f:\n",
    "    items_data = [json.loads(line) for line in f]\n",
    "with open('files/RI разметка/3 итерация/data_vector_gt_1000.txt', 'r') as f:\n",
    "    ground_truth = f.read().strip().splitlines()\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, item in enumerate(items_data):\n",
    "    # print(type(item[1]))\n",
    "    # print(item[2])\n",
    "    request = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "Ты помощник поиска в маркетплейсе.\n",
    "Тебе необходимо определить, соответствует ли товар и его характеристики поисковому запросу.\n",
    "Классы запросов:\n",
    "- relevant: товары, которые можно купить по указанному запросу\n",
    "- irrelevant: товары, которые было бы странно увидеть по указанному запросу\n",
    "Обязательно учитывай, чтобы характеристики товара, указанные в запросе, совпадали с характеристиками товара.\n",
    "Товар:\n",
    "{item[1]['товар']}\n",
    "Характеристика товара:\n",
    "{item[3][\"характеристики\"]}\n",
    "Запрос:\n",
    "{item[2]['запрос']}\n",
    "Определи релевантность запроса товару. Отвечай только \"relevant\" или \"irrelevant\". Не пиши объяснений и ничего больше.\n",
    "\"\"\"\n",
    "    }\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen32b\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \n",
    "             \"content\": \"You are a helpful AI assistant\"},\n",
    "            request\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=3,\n",
    "    )\n",
    "    \n",
    "    prediction = response.choices[0].message.content.strip().lower()\n",
    "    \n",
    "    # сравниваю предсказание с правильным ответом, исключая #N/A\n",
    "    ground_truth_label = ground_truth[i].strip().lower()\n",
    "    if ground_truth_label != '#n/a':\n",
    "        is_correct = prediction == ground_truth_label\n",
    "        results.append({\n",
    "            \"запрос\": item[2]['запрос'],\n",
    "            \"товар\": item[1]['товар'],\n",
    "            \"предсказание\": prediction,\n",
    "            \"реальность\": ground_truth_label,\n",
    "            \"is_correct\": is_correct\n",
    "        })\n",
    "\n",
    "# Подсчет общей Accuracy\n",
    "count_correct = sum(1 for item in results if item['is_correct'] == True)\n",
    "total_predictions = len(results)\n",
    "accuracy = count_correct / total_predictions if total_predictions > 0 else 0\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Accuracy для relevant\n",
    "relevant_correct = sum(1 for item in results if item['реальность'] == 'relevant' and item['is_correct'])\n",
    "relevant_total = sum(1 for item in results if item['реальность'] == 'relevant')\n",
    "relevant_accuracy = relevant_correct / relevant_total if relevant_total > 0 else 0\n",
    "\n",
    "# Accuracy для irrelevant\n",
    "irrelevant_correct = sum(1 for item in results if item['реальность'] == 'irrelevant' and item['is_correct'])\n",
    "irrelevant_total = sum(1 for item in results if item['реальность'] == 'irrelevant')\n",
    "irrelevant_accuracy = irrelevant_correct / irrelevant_total if irrelevant_total > 0 else 0\n",
    "\n",
    "print(f\"Accuracy for relevant: {relevant_accuracy:.2%}\")\n",
    "print(f\"Accuracy for irrelevant: {irrelevant_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d83da3-9ecb-4468-93b3-dc85299a6930",
   "metadata": {},
   "source": [
    "# gemma-2-9b-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e934e44d-36b1-4351-8b55-2a3268093303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.81%\n",
      "Accuracy for relevant: 99.17%\n",
      "Accuracy for irrelevant: 4.88%\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "client = openai.Client(base_url=\"http://127.0.0.1:30000/v1\", api_key=\"None\")\n",
    "\n",
    "# загружаю файлы (с примерами и правильными ответами)\n",
    "with open('files/RI разметка/3 итерация/items_1000.jsonl', 'r') as f:\n",
    "    items_data = [json.loads(line) for line in f]\n",
    "with open('files/RI разметка/3 итерация/data_vector_gt_1000.txt', 'r') as f:\n",
    "    ground_truth = f.read().strip().splitlines()\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, item in enumerate(items_data):\n",
    "    # print(type(item[1]))\n",
    "    # print(item[2])\n",
    "    request = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "Ты помощник поиска в маркетплейсе.\n",
    "Тебе необходимо определить, соответствует ли товар и его характеристики поисковому запросу.\n",
    "Классы запросов:\n",
    "relevant - товары, которые можно купить по указанному запросу\n",
    "irrelevant - товары, которые было бы странно увидеть по указанному запросу\n",
    "Товар:\n",
    "{item[1]['товар']}\n",
    "Запрос:\n",
    "{item[2]['запрос']}\n",
    "Определи релевантность запроса товару. Отвечай только \"relevant\" или \"irrelevant\". Не пиши объяснений и ничего больше.\n",
    "\"\"\"\n",
    "    }\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gemma-2-9b-it\",\n",
    "        messages=[\n",
    "            request\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=3,\n",
    "    )\n",
    "    \n",
    "    prediction = response.choices[0].message.content.strip().lower()\n",
    "    \n",
    "    # сравниваю предсказание с правильным ответом, исключая #N/A\n",
    "    ground_truth_label = ground_truth[i].strip().lower()\n",
    "    if ground_truth_label != '#n/a':\n",
    "        is_correct = prediction == ground_truth_label\n",
    "        results.append({\n",
    "            \"запрос\": item[2]['запрос'],\n",
    "            \"товар\": item[1]['товар'],\n",
    "            \"предсказание\": prediction,\n",
    "            \"реальность\": ground_truth_label,\n",
    "            \"is_correct\": is_correct\n",
    "        })\n",
    "\n",
    "# Подсчет общей Accuracy\n",
    "count_correct = sum(1 for item in results if item['is_correct'] == True)\n",
    "total_predictions = len(results)\n",
    "accuracy = count_correct / total_predictions if total_predictions > 0 else 0\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Accuracy для relevant\n",
    "relevant_correct = sum(1 for item in results if item['реальность'] == 'relevant' and item['is_correct'])\n",
    "relevant_total = sum(1 for item in results if item['реальность'] == 'relevant')\n",
    "relevant_accuracy = relevant_correct / relevant_total if relevant_total > 0 else 0\n",
    "\n",
    "# Accuracy для irrelevant\n",
    "irrelevant_correct = sum(1 for item in results if item['реальность'] == 'irrelevant' and item['is_correct'])\n",
    "irrelevant_total = sum(1 for item in results if item['реальность'] == 'irrelevant')\n",
    "irrelevant_accuracy = irrelevant_correct / irrelevant_total if irrelevant_total > 0 else 0\n",
    "\n",
    "print(f\"Accuracy for relevant: {relevant_accuracy:.2%}\")\n",
    "print(f\"Accuracy for irrelevant: {irrelevant_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed34f677-e122-4360-b7a1-3b373ea5fd18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f983942-a5b1-4c4c-956c-c0a4e89e7aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
